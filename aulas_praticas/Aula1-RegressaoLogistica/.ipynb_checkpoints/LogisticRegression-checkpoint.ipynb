{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regressão Logística"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regressão logística é uma técnica de classificação que pertence ao grupo dos classificadores lineares* e de alguma forma parecida com regressão linear. É uma técnica rápida e simples de entender, além de conveniente para interpretar os resultados. Apesar de ser, essencialmente, um método para classificação binária, pode ser usado para classificação multi-classes.\n",
    "\n",
    "\\* classificação baseada em uma combinação linear entre as variáveis de entrada, também chamado de _logit_.\n",
    "\n",
    "ex: $f(X) = \\alpha + b_1x_1 + b_2x_2 +\\dots + b_nx_n$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Função Sigmoid\n",
    "\n",
    "O objetivo da Regressão Logística é encontrar a função $p($**x**$)$ tal que as saídas estimadas $p(x_i)$ fiquem o mais próximo possível do valor real de $y_i$ para cada amostra $i = 1, 2, \\dots, n$. Como, em um primeiro momento, vamos lidar exclusivamente de classificação binária, essas saídas devem ser apenas $0$ ou $1$. Sendo assim, é conveniente utilizar a função Sigmoid (caso especial da função logística).\n",
    "\n",
    "<img src=\"assets/log-reg-1.webp\" alt=\"sigmoid\" width=\"400\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Juntando a combinação linear com a função Sigmoid\n",
    "\n",
    "A Regressão logística determina os melhores valores para o bias $\\alpha$ e os pesos $b_1, b_2, \\dots, b_n$, tal que a função $p($**x**$)$ se aproxime da classe real da amostra. O processo de encontrar os melhores valores para esses parâmetros é chamado de treinamento (ou _fitting_ ).\n",
    "\n",
    "Nesse caso, **x** que a função Sigmoid ($p$) recebe é a saída da combinação linear $f(X) = \\alpha + b_1x_1 + b_2x_2 +\\dots + b_nx_n$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Como encontrar os melhores valores para o bias e os pesos?\n",
    "\n",
    "Os melhores pesos são geralmente encontrados maximizando a função de verosimilhança logarítmica (_log-likelihood_ ) O método é chamado de maximização da verossimilhança (_maximum likelihood estimation_ - MLE) e é representado pela seguinte equação.\n",
    "\n",
    "\\begin{equation}\n",
    "MLE = \\sum_{i=1}^n(y_i log(p(x_i)) + (1 − y_i) log(1 − p(x_i))).\n",
    "\\end{equation}\n",
    "<img src=\"assets/log-reg-4.webp\" alt=\"log\" width=\"400\"/>\n",
    "\n",
    "Os melhores parâmetros para maximizar essa equação podem ser encontrados usando técnicas matemáticas, essa parte será executada pelo scikit-learn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementação\n",
    "\n",
    "### Exemplo 1 - Classificação binária com uma única variável de entrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Passo n° 1: Importando as bibliotecas necessárias\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x = [[0]\n",
      " [1]\n",
      " [2]\n",
      " [3]\n",
      " [4]\n",
      " [5]\n",
      " [6]\n",
      " [7]\n",
      " [8]\n",
      " [9]]\n",
      "y = [0 0 0 0 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "# Passo n° 2: Gerando dados para classificação\n",
    "\n",
    "# Gerando os dados de entrada. Serão geradas 10 amostras com valores de 0 a 9\n",
    "# note que os modelos do scikit-learn esperam um array composto com um array de características\n",
    "# por amostra de entrada (mesmo que seja apenas 1 característica). Por isso fazemos um reshape.\n",
    "x = np.arange(10).reshape(-1, 1) \n",
    "\n",
    "# gerando as classes para cada amostra\n",
    "y = np.array([0, 0, 0, 0, 1, 1, 1, 1, 1, 1])\n",
    "print('x = {}'.format(x))\n",
    "print('y = {}'.format(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=0, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Passo n° 3: Criando e treinando um modelo\n",
    "\n",
    "# Criando ou estanciando o modelo:\n",
    "#   solver é o algoritmo utilizado para otimizar os parâmetros.\n",
    "#     liblinear é a melhor opção para datasets pequenos e binários.\n",
    "#   random_state = 0, ou qualquer número, garante que a inicialização aleatória vai ser sempre igual, \n",
    "#     independente de quantas vezes rodar o algoritmo\n",
    "model = LogisticRegression(solver='liblinear', random_state=0)\n",
    "\n",
    "# O modelo possui diversos hiperparâmetros que podem ser ajustados, como penalidade (padrão L2), número \n",
    "#   de iterações, etc. Sugiro que deem uma olhada na documentação:\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "\n",
    "# Treinando o modelo\n",
    "model.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classes = [0 1]\n",
      "bias = [-1.04608067]\n",
      "pesos = [[0.51491375]]\n"
     ]
    }
   ],
   "source": [
    "# Podemos extrair algumas informações do modelo, como por exemplo:\n",
    "\n",
    "# as classes presentes no conjunto de dados\n",
    "print('classes = {}'.format(model.classes_))\n",
    "\n",
    "# o valor do bias\n",
    "print('bias = {}'.format(model.intercept_))\n",
    "\n",
    "# os pesos\n",
    "print('pesos = {}'.format(model.coef_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probabilidades = [[0.74002157 0.25997843]\n",
      " [0.62975524 0.37024476]\n",
      " [0.5040632  0.4959368 ]\n",
      " [0.37785549 0.62214451]\n",
      " [0.26628093 0.73371907]\n",
      " [0.17821501 0.82178499]\n",
      " [0.11472079 0.88527921]\n",
      " [0.07186982 0.92813018]\n",
      " [0.04422513 0.95577487]\n",
      " [0.02690569 0.97309431]]\n",
      "\n",
      "classe_estimada = [0 0 0 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "# Passo n° 4: Avaliando o modelo\n",
    "\n",
    "# uma das formas de avaliar o modelo, é através a probabilidade  que ele dá à cada amostra\n",
    "#   de pertencer a cada classe\n",
    "probabilidades = model.predict_proba(x)\n",
    "\n",
    "# uma outra forma mais comum é através da classe que o modelo estimou\n",
    "classe_estimada = model.predict(x)\n",
    "\n",
    "print('probabilidades = {}\\n'.format(probabilidades))\n",
    "print('classe_estimada = {}'.format(classe_estimada))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos visualizar essa classificação na figura a seguir:\n",
    "<img src=\"assets/log-reg-5.webp\" alt=\"univariate\" width=\"800\"/>\n",
    "\n",
    "Note que a classificação corresponde ao limiar $p(x) = 0.5$, que ocorre quando $f(x) = 0$. Esse valor é o limite da classificação entre as classe $0$ e $1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# uma outra métrica bem interessante é a acurácia, ou taxa de acerto do nosso modelo, \n",
    "#   que pode ser computada da seguinte maneira:\n",
    "\n",
    "# esse valor representa a relação entre o número de acertos dividido pelo número total de amostras.\n",
    "#   caso acerte todas as predições, o resultado é igual a 1.\n",
    "model.score(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matriz de confusão\n",
    "\n",
    "A matriz de confusão permite obter informações mais detalhadas sobre o resultado da classificação, levando em conta a taxa de acerto de cada classe. Nesse caso, utilizamos 4 novas métricas:\n",
    "\n",
    "- Verdadeiros Negativos (True negatives - **TN**): amostras negativas (zeros) estimadas corretamente\n",
    "- Verdadeiros Positivos (True positives - **TP**): amostras positivas (1's) estimadas corretamente\n",
    "- Falsos Negativos (False negatives - **FN**): amostras negativas (zeros) estimadas incorretamente\n",
    "- Falsos Positivos (False positives - **FP**): amostras positivas (1's) estimadas incorretamente\n",
    "\n",
    "A matriz de confusão mostra esses valores da seguinte forma:\n",
    "\n",
    "- **TN**: no canto superior esquerdo\n",
    "- **FN**: no canto inferior esquerdo\n",
    "- **FP**: no canto superior direito\n",
    "- **TP**: no canto inferior direito"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CM = \n",
      "[[3 1]\n",
      " [0 6]]\n"
     ]
    }
   ],
   "source": [
    "# podemos computar a matriz de confusão da seguinte maneira\n",
    "\n",
    "# poderiamos usar model.predict(x), mas já temos os resultados das predições na variável classe_estimada\n",
    "cm = confusion_matrix(y, classe_estimada)\n",
    "print('CM = ')\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A primeira linha da matriz de confusão mostra que 3 amostras da classe zero foram classificadas como classe zero, enquanto 1 amostra da classe zero foi classificada erroneamente como classe 1.\n",
    "\n",
    "Do mesmo modo, a segunda linha mostra que nenhuma amostra da classe 1 foi classificada erroneamente como classe 0, pois todas as amostras (6) da classe 1 foram classificadas corretamente.\n",
    "\n",
    "Podemos plotar a matriz de confusão para ter uma melhor visualização desses resultados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe8AAAHSCAYAAADFbUO+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAAXG0lEQVR4nO3dedRddX3v8c83YQhTBhEtMiiOiGi1orVahzrgrFXrcItTe621tzi2Dst6vVSpy6vtba+t7b04LKsiXrVanHHACsUBUJBRXAhVQUUsYYgkQMjv/vHsaAjBhAycfB9fr7XOyjn77OH3JGc/77P3Ps+TGmMEAOhjwawHAADcPOINAM2INwA0I94A0Ix4A0Az4g0Azeww6wFsC7ssXjb2uM0+sx4GzFu32W2nWQ8B5r2zzzjtp2OMvTb03LyM9x632SdPf8uHZj0MmLcOf8DtZz0EmPcO2mf3793Uc06bA0Az4g0AzYg3ADQj3gDQjHgDQDPiDQDNiDcANCPeANCMeANAM+INAM2INwA0I94A0Ix4A0Az4g0AzYg3ADQj3gDQjHgDQDPiDQDNiDcANCPeANCMeANAM+INAM2INwA0I94A0Ix4A0Az4g0AzYg3ADQj3gDQjHgDQDPiDQDNiDcANCPeANCMeANAM+INAM2INwA0I94A0Ix4A0Az4g0AzYg3ADQj3gDQjHgDQDPiDQDNiDcANCPeANCMeANAM+INAM2INwA0I94A0Ix4A0Az4g0AzYg3ADQj3gDQjHgDQDPiDQDNiDcANCPeANCMeANAM+INAM2INwA0I94A0Ix4A0Az4g0AzYg3ADQj3gDQjHgDQDPiDQDNiDcANCPeANCMeANAM+INAM2INwA0I94A0Ix4A0Az4g0AzYg3ADQj3gDQjHgDQDPiDQDNiDcANCPeANCMeANAM+INAM2INwA0I94A0Ix4A0Az4g0AzYg3ADQj3gDQjHgDQDPiDQDNiDcANCPeANCMeANAM+INAM2INwA0I94A0Ix4A0Az4g0AzYg3ADSzw6wHwK+m7371uJz+iffm8osvzOprVmaPvW6Xuz70ibnPk/8wC3fcadbDg3nhexd+N+/+p7/Lt755cs4/79zc9zcfmH/+yGdnPSy2AvFmJlZddUX2Pfj+uc+T/yA777pHLjn/zJzyoX/M1ct/mof80etmPTyYF87/zrk58fjP5V6/cb+svu66WQ+HrUi8mYl7HPqMGzze556/mWuv/lnO+uwxefAL/iJVNaORwfzxO496XB7x6CckSV72R4dl+fL/nPGI2Fpc82a7sWiPJVmz2tEBbC0LFvgWP19t9F+2qh5TVedV1flV9ZpbYlDTdg+pqrfdUttjNtZcf32uu2ZlfnTuN3Lmp4/OPR79TEfdABvxS0+bV9XCJG9P8qgkFyU5pao+PsY45+ZspKp2GGOsvjnLjDFOTXLqzVmGft5x2CG5/rprkyR3e9iT8sDn/vmMRwSw/dvYkff9k5w/xrhgjHFtkg8meXKSVNWbq+qcqjqjqv56/QWr6oiqel9VnZTkfVW1V1X9S1WdMt0eNM13/6r6alWdVlVfqaq7TdMfVlWfnO4/tKpOn26nVdUeW/HvgBl66puOzlOOfG8e+LxX5sKTv5QT3nnkrIcEsN3b2AfW9knyg3UeX5TkN6tqzyRPSXLgGGNU1dKbWP6gJL89xlhZVR9I8rdjjH+vqv2THJfk7km+neTBY4zVVfXIJG9K8rT11vPnSf50jHFSVe2eZNXN+BrZju11x4OSJHvf/b5ZtHhZjv/71+beT3p+lvza/jMeGcD2a3M/bX5F5gL6runo+JM3Md/Hxxgrp/uPTHLQOtczF08hXpLkn6vqLklGkh03sJ6Tkvyvqjo6yUfHGBetP0NVvTDJC5Nk91vvvXlfFTO1NuRXXnKxeAP8Ehs7bX5xkv3Webxvkoun69f3T/KRJE9IclM/9f+z9bb1gDHGvafbPmOMFUnemORLY4yDkzwxyaL1VzLGeHOSFyTZJclJVXXgBuY5aoxxyBjjkF2W3GojXxbbox9/+7QkyeLb7jPjkQBs3zZ25H1KkrtU1QGZC/mzkvz+dMS86xjj09M17Qs2YVufS/LiJG9Nkqq69xjj9MwdeV88zfP8DS1YVXcaY5yZ5Myqul+SAzN3up2mPvHGF2bfe/1WbrXfnVMLFuTH3z4tp3/iPbnzgx7rqBu2kpUrr84JXzwuSXLJj3+UFSuuzHGf/FiS5CGPeHR22WXXWQ6PLfBL4z1dhz48c9enFyZ59xjj7KraO8mxVbUoSSV5xSZs6yVJ3l5VZ0zbPSHJi5K8JXOnzV+X5FM3sezLqup3kqxJcnaSz2zC9tiO3ebOB+e8L/1rrrz04ixYsEMW33bfPOCwl9/ol7cAm++yn16al//xc24wbe3jz3/t7Oyz3+1nMSy2ghpjzHoMW91t7nzwePpbPjTrYcC8dfgDfNOHbe2gfXb/xhjjkA0959fvAEAz4g0AzYg3ADQj3gDQjHgDQDPiDQDNiDcANCPeANCMeANAM+INAM2INwA0I94A0Ix4A0Az4g0AzYg3ADQj3gDQjHgDQDPiDQDNiDcANCPeANCMeANAM+INAM2INwA0I94A0Ix4A0Az4g0AzYg3ADQj3gDQjHgDQDPiDQDNiDcANCPeANCMeANAM+INAM2INwA0I94A0Ix4A0Az4g0AzYg3ADQj3gDQjHgDQDPiDQDNiDcANCPeANCMeANAM+INAM2INwA0I94A0Ix4A0Az4g0AzYg3ADQj3gDQjHgDQDPiDQDNiDcANCPeANCMeANAM+INAM2INwA0I94A0Ix4A0Az4g0AzYg3ADQj3gDQjHgDQDPiDQDNiDcANCPeANCMeANAM+INAM2INwA0I94A0Ix4A0Az4g0AzYg3ADQj3gDQjHgDQDPiDQDNiDcANCPeANCMeANAM+INAM2INwA0I94A0Ix4A0Az4g0AzYg3ADQj3gDQjHgDQDPiDQDNiDcANCPeANCMeANAM+INAM2INwA0I94A0Ix4A0Az4g0AzYg3ADQj3gDQjHgDQDPiDQDNiDcANLPDrAewLey3ZFH+5kkHzXoYMG8tu9/hsx4C/Epz5A0AzYg3ADQj3gDQjHgDQDPiDQDNiDcANCPeANCMeANAM+INAM2INwA0I94A0Ix4A0Az4g0AzYg3ADQj3gDQjHgDQDPiDQDNiDcANCPeANCMeANAM+INAM2INwA0I94A0Ix4A0Az4g0AzYg3ADQj3gDQjHgDQDPiDQDNiDcANCPeANCMeANAM+INAM2INwA0I94A0Ix4A0Az4g0AzYg3ADQj3gDQjHgDQDPiDQDNiDcANCPeANCMeANAM+INAM2INwA0I94A0Ix4A0Az4g0AzYg3ADQj3gDQjHgDQDPiDQDNiDcANCPeANCMeANAM+INAM2INwA0I94A0Ix4A0Az4g0AzYg3ADQj3gDQjHgDQDPiDQDNiDcANCPeANCMeANAM+INAM2INwA0I94A0Ix4A0Az4g0AzYg3ADQj3gDQjHgDQDPiDQDNiDcANCPeANCMeANAM+INAM2INwA0I94A0Ix4A0Az4g0AzYg3ADQj3gDQjHgDQDPiDQDNiDcANCPeANCMeANAM+INAM2INwA0I94A0Ix4A0Az4g0AzYg3ADQj3gDQjHgDQDPiDQDNiDczc+455+Sxhz4it1q8aw7Y/3Z5wxGvz/XXXz/rYcG8MsaarL7kG7nmnPdn1bf+KavOfk+uu/jfZz0sttAOsx4Av5qWL1+exz3mkbn73Q/Khz96bC747nfzmlf9WdasWZMj3nDkrIcH88Z13/9i1lx1UXb4tftlwaJlGdeuyJpVl816WGwh8WYm3nnU/8mqlSvzwQ9/NIsXL84jHvmoXHnVlfmrNxyRV/z5q7J48eJZDxHau/7K72XN8vOz04HPzIJFt/r59IUzHBNbx0ZPm1fVu6vqJ1V11i0xoHW2e7uq+sgtuU1uOcd99jN55KGPvkGkn/6MZ2XlypU58YQvz3BkMH9cf9m5WbDHPjcIN/PDplzzfk+Sx2zJRqrqZh/hjzF+OMb4vS3ZLtuv75z37dztbgfeYNr++++fXXfdNeed9+0ZjQrmlzU/uyS189Jcd9EJWXXGUVn1rf+bay/8TMZ1P5v10NhCG433GOOEJDe6QFJVL6mqc6rqjKr64Aaef35Vfbyqjk/yxarabTqKP7mqTquqJ0/z3aGqTqyqb063B64z/azp/j2m5U6ftneXLf3Cma3ly5dnyZKlN5q+dNmyXL58+S0/IJiPVl+d6y/7dtas/Gl2vMOh2XH/h2fN1T/JtRd+OmOMWY+OLbAl17xfk+SAMcY1VbX0Jub5jST3GmNcVlVvSnL8GOMPp/lPrqovJPlJkkeNMVZNUT4mySHrredFSf73GOPoqtopLtkAbKKRnQ54XGqHRUmS2nG3XHv+x7JmxUVZuMd+Mx4bm2tLflTsjCRHV9Wzk6y+iXk+P8ZYe9R+aJLXVNXpSf4tyaIk+yfZMck7qurMJB9OctAG1vPVJK+tqlcnuf0YY+X6M1TVC6vq1Ko69dKfXroFXxa3hGXLluXKK6+40fTLly/P0mXLZjAimIcW7pxatOfPw50ktdveSS3IWOUMV2dbEu/HJ3l75o6uT7mJ69rrXlipJE8bY9x7uu0/xjg3ycuTXJLk1zN3xL3T+isZY3wgyZOSrEzy6ap6+AbmOWqMccgY45C9br3XFnxZ3BLuercDb3Rt+wc/+EGuvvrqG10LBzZP7fzL3gjXLTYOtr7NindVLUiy3xjjS0lenWRJkt03sthxSV5cVTWt4z7T9CVJfjTGWJPkOdnAKfGqumOSC8YYb0tybJJ7bc642X48+jGPzRc+d1yuuuqqn0/7yIf/X3bZZZc8+CEPneHIYP5YuOQOGav+M2P1L05Wrlnxw2SsyYJd9pzhyNhSm/KjYsdk7rT13arqoqr6r5kL7PunU92nJXnbGOPyjazqjZk7RX5GVZ09PU6Sf0zyvKr6VpIDc8Oj9bWekeSs6ZT7wUneu7Fxs317wQtflJ133jnPevpTc/wXv5B3veOo/NUbjshLXvYKP+MNW8nCPe+RLFyUay/4VK6/4sJcv/w7ue77X8iC3ffNgt1vN+vhsQVqPn7i8L73PWSc9PVTZz0MNuLcc87Jy196eL7+ta9m6dKlef4fviCve/0RWbjQ5xG3d8vud/ish8AmWnPN5Vl90YlZ87MfJrUwCxYfkB33edANroOzfVp1+tu/McZY/wPcSfyGNWbo7gcdlM9+/vhZDwPmtQU7L81Od3rirIfBVuY/JgGAZsQbAJoRbwBoRrwBoBnxBoBmxBsAmhFvAGhGvAGgGfEGgGbEGwCaEW8AaEa8AaAZ8QaAZsQbAJoRbwBoRrwBoBnxBoBmxBsAmhFvAGhGvAGgGfEGgGbEGwCaEW8AaEa8AaAZ8QaAZsQbAJoRbwBoRrwBoBnxBoBmxBsAmhFvAGhGvAGgGfEGgGbEGwCaEW8AaEa8AaAZ8QaAZsQbAJoRbwBoRrwBoBnxBoBmxBsAmhFvAGhGvAGgGfEGgGbEGwCaEW8AaEa8AaAZ8QaAZsQbAJoRbwBoRrwBoBnxBoBmxBsAmhFvAGhGvAGgGfEGgGbEGwCaEW8AaEa8AaAZ8QaAZsQbAJoRbwBoRrwBoBnxBoBmxBsAmhFvAGhGvAGgGfEGgGbEGwCaEW8AaEa8AaAZ8QaAZsQbAJoRbwBoRrwBoBnxBoBmxBsAmhFvAGhGvAGgGfEGgGbEGwCaEW8AaEa8AaAZ8QaAZsQbAJoRbwBoRrwBoBnxBoBmxBsAmhFvAGhGvAGgGfEGgGbEGwCaEW8AaEa8AaAZ8QaAZsQbAJoRbwBoRrwBoBnxBoBmxBsAmhFvAGimxhizHsNWV1WXJvnerMfBzXLrJD+d9SBgHrOP9XP7McZeG3piXsabfqrq1DHGIbMeB8xX9rH5xWlzAGhGvAGgGfFme3HUrAcA85x9bB5xzRsAmnHkDQDNiDdJkqp6TFWdV1XnV9VrttE2llbVf1vn8e2q6iPbaFsrtsV6YXNV1bur6idVddY23s5r13v8lW20nf+oqltvi3WzcU6bk6pamOQ7SR6V5KIkpyT5L2OMc7bydu6Q5JNjjIO35npvYlsrxhi7b+vtwKaqqockWZHkvdtyH7ilXvtV9R9JDhlj+NnxGXDkTZLcP8n5Y4wLxhjXJvlgkicnSVW9uarOqaozquqv11+wqnabjihOrqrTqmrtcveYpp0+LXuXJG9Ocqdp2lur6g5rj0Kq6vlV9a9V9fnpHf3hVfWKaZ1fq6pbTfP9UVWdUlXfqqp/qapdp+kHVNVXq+rMqjpynfHVtK2zpueeOU3fu6pOmMZyVlU9eJv+DfMrb4xxQpLL1p9eVS9ZZx/74AaeXzi9hk+Z5vnjafqNXsNV9eYku0zTjp7mWzH9+bCq+nJVHVtVF0z79mHTfnpmVd1pmu+JVfX1ad/7QlXddpq+Z1V9rqrOrqp3Jql1xviKaQxnVdXLpmm7VdWnpn31rLX7HlvJGMPtV/yW5PeSvHOdx89J8g9J9kxyXn5xhmbpBpZ9U5Jnr30+c0fwuyX5+ySHTdN3SrJLkjskOWudZX/+OMnzk5yfZI8keyW5IsmLpuf+NsnLpvt7rrP8kUlePN3/eJLnTvf/NMmK6f7Tknw+ycIkt03y/SR7J/mzJH8xzbMwyR6z/ndwm/+39feBadoPk+w83V+6gWVemOR10/2dk5ya5ICbeg2vfe2vs/zafeFhSS6fXv87J7k4yV9Oz700yd9N95ets8+/IMnfTPffluT10/3HJxmZ+61t901y5rTf757k7CT3mfa9d6wzjiWz/vufTzdH3vwyVyRZleRdVfXUJFdvYJ5Dk7ymqk5P8m9JFiXZP8lXk7y2ql6duV/xt3ITtvelMcZVY4xLp21/Ypp+Zua+6SXJwVV1YlWdmeSwJPeYpj8oyTHT/fets87fTnLMGOP6McYlSb6c5H6ZuzTwB1V1RJJ7jjGu2oTxwbZwRpKjq+rZSVZv4PlDkzx32se+nrk31XfJ5r2GTxlj/GiMcU2S7yb53DR93X1s3yTHTfvYK/OLfewhSd6fJGOMTyVZPk3/7SQfG2P8bIyxIslHkzx4Wuejqup/VtWDxxhXbML42ETiTTL3Dny/dR7vm+TiMcbqzJ1S/0iSJyT57AaWrSRPG2Pce7rtP8Y4d4zxgSRPSrIyyaer6uGbMI5r1rm/Zp3Ha5LsMN1/T5LDxxj3TPKXmXuzsNYmf4BjzJ3CfEjmvvb3VNVzN3VZ2Moen+TtSX4jySlVtcN6z1fmzjCt3ccOGGN8bjNfw5uyj/19kn+Y9rE/zg33sU02xvjO9DWdmeTIqnr95qyHDRNvkrl38HeZrhvvlORZST5eVbtn7lTXp5O8PMmvb2DZ45K8uKoqSarqPtOfd0xywRjjbUmOTXKvJFdl7rT4ltgjyY+qasfMHXmvddI07qw3/cQkz5yuG+6VuW92J1fV7ZNcMsZ4R5J3Zu6bDNyiqmpBkv3GGF9K8uokSzJ36nldxyX5k+k1n6q663Q9+aZew9etnXczLcncG4Iked46009I8vvTGB6budPrydw+9rtVtWtV7ZbkKUlOrKrbJbl6jPH+JG+NfWyrWv8dHr+Cxhirq+rwzH2TWJjk3WOMs6tq7yTHVtWizL37f8UGFn9jkr9Lcsb0jejCzB2lPyPJc6rquiQ/TvKmMcZlVXVSzX1I7TOZO9q4uf575k4dXjr9ufbNwEuTfGA6TX/sOvN/LMlvJflW5o7MXzXG+HFVPS/JK6fxrUjiyJttqqqOydx151tX1UVJ/keS9yZ5f1Utydw+9rYxxuXrLfrOzJ3S/ub0JvnSJL87rWtDr+GjMrc/fnOMcVhuviOSfLiqlic5PnPX15O5M13HVNXZSb6Suc+PZIzxzap6T5KT1453jHFaVT06yVurak2S65L8yWaMhZvgR8UAoBmnzQGgGfEGgGbEGwCaEW8AaEa8AaAZ8QaAZsQbAJoRbwBo5v8D3/teucuPkFUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "ax.imshow(cm, cmap=plt.cm.Blues)\n",
    "ax.grid(False)\n",
    "ax.xaxis.set(ticks=(0, 1), ticklabels=('0s estimados', '1s estimados'))\n",
    "ax.yaxis.set(ticks=(0, 1), ticklabels=('0s reais', '1s reais'))\n",
    "ax.set_ylim(1.5, -0.5)\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        ax.text(j, i, cm[i, j], ha='center', va='center',  size=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos também obter um relatório mais detalhado da classificação utilizando a função classification_report():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.75      0.86         4\n",
      "           1       0.86      1.00      0.92         6\n",
      "\n",
      "    accuracy                           0.90        10\n",
      "   macro avg       0.93      0.88      0.89        10\n",
      "weighted avg       0.91      0.90      0.90        10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y, classe_estimada))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Onde as métricas representam:\n",
    "\n",
    "- **Precisão** = TP/TP+FP ou TN/TN+FN -> Taxa de acerto considerando todas as amostras classificadas como sendo da classe.\n",
    "- **Recall** = TP/TP+FN ou TN/TN+FP -> Taxa de quantas amostras da classe foram corretamente classificadas.\n",
    "- **F1, Macro AVG e Weighted AVG** -> Similar a acurácia, mas são ponderadas pelo número de amostras por classes.\n",
    "- **support** -> número de amostras consideradas em cada caso\n",
    "\n",
    "<img src=\"assets/prec_rec.png\" alt=\"prec_rec\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Melhorando nosso modelo\n",
    "\n",
    "Podemos melhorar o modelo alterando alguns dos hiper-parâmetros. Podemos, por exemplo, alterar o valor do hiper-parâmetro C (um valor de regularização) de $1.0$ (padrão) para $10.0$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(solver='liblinear', C=10.0, random_state=0).fit(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essa mudança já é capaz de gerar diferentes probabilidades:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bias =  [-3.51335372]\n",
      "pesos =  [[1.12066084]]\n",
      "probabilidades =  [[0.97106534 0.02893466]\n",
      " [0.9162684  0.0837316 ]\n",
      " [0.7810904  0.2189096 ]\n",
      " [0.53777071 0.46222929]\n",
      " [0.27502212 0.72497788]\n",
      " [0.11007743 0.88992257]\n",
      " [0.03876835 0.96123165]\n",
      " [0.01298011 0.98701989]\n",
      " [0.0042697  0.9957303 ]\n",
      " [0.00139621 0.99860379]]\n",
      "classes estimadas =  [0 0 0 0 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print('bias = ',model.intercept_)\n",
    "print('pesos = ',model.coef_)\n",
    "print('probabilidades = ',model.predict_proba(x))\n",
    "print('classes estimadas = ',model.predict(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essa regularização gerou valores mais significativos nos bias e nos pesos, implicando em uma mudança na nossa função logit $f(x)$. Essa mudança também foi importante para distorcer a nossa função sigmoid, sendo que agora o valor de limiar ($p(x)=0.5$) foi deslocado mais para a direita, como mostrado na figura a seguir:\n",
    "\n",
    "<img src=\"assets/log-reg-7.webp\" alt=\"regularized\" width=\"600\"/>\n",
    "\n",
    "printando novamente nosso relatório, podemos observar que dessa vez obtemos o valor máximo em todas as métricas, indicando que a classificação foi $100%$ satisfatória."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acurácia =  1.0\n",
      "matriz de confusão = \n",
      "[[4 0]\n",
      " [0 6]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         4\n",
      "           1       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           1.00        10\n",
      "   macro avg       1.00      1.00      1.00        10\n",
      "weighted avg       1.00      1.00      1.00        10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('acurácia = ', model.score(x, y))\n",
    "print('matriz de confusão = ')\n",
    "print( confusion_matrix(y, model.predict(x)))\n",
    "print(classification_report(y, model.predict(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exemplo 2 - Similar ao exemplo 1, mudando apenas a classe da segunda amostra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Passo 1: importando os pacotes e classes\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Passo 2: Gerando os dados\n",
    "x = np.arange(10).reshape(-1, 1)\n",
    "y = np.array([0, 1, 0, 0, 1, 1, 1, 1, 1, 1])\n",
    "\n",
    "# Passo 3: Criando e treinando o modelo\n",
    "model = LogisticRegression(solver='liblinear', C=10.0, random_state=0)\n",
    "model.fit(x, y)\n",
    "\n",
    "# Passo 4: avaliando o modelo\n",
    "p_pred = model.predict_proba(x)\n",
    "y_pred = model.predict(x)\n",
    "score_ = model.score(x, y)\n",
    "conf_m = confusion_matrix(y, y_pred)\n",
    "report = classification_report(y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "visualizando os resultados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x:\n",
      "[[0]\n",
      " [1]\n",
      " [2]\n",
      " [3]\n",
      " [4]\n",
      " [5]\n",
      " [6]\n",
      " [7]\n",
      " [8]\n",
      " [9]]\n",
      "y:\n",
      "[0 1 0 0 1 1 1 1 1 1]\n",
      "\n",
      "bias: [-1.51632619]\n",
      "pesos: [[0.703457]]\n",
      "\n",
      "probabilidades:\n",
      "[[0.81999686 0.18000314]\n",
      " [0.69272057 0.30727943]\n",
      " [0.52732579 0.47267421]\n",
      " [0.35570732 0.64429268]\n",
      " [0.21458576 0.78541424]\n",
      " [0.11910229 0.88089771]\n",
      " [0.06271329 0.93728671]\n",
      " [0.03205032 0.96794968]\n",
      " [0.0161218  0.9838782 ]\n",
      " [0.00804372 0.99195628]]\n",
      "\n",
      "classes estimadas: [0 0 0 1 1 1 1 1 1 1]\n",
      "\n",
      "acurácia: 0.8\n",
      "\n",
      "matriz de confusão:\n",
      "[[2 1]\n",
      " [1 6]]\n",
      "\n",
      "relatório:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.67      0.67         3\n",
      "           1       0.86      0.86      0.86         7\n",
      "\n",
      "    accuracy                           0.80        10\n",
      "   macro avg       0.76      0.76      0.76        10\n",
      "weighted avg       0.80      0.80      0.80        10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('x:', x, sep='\\n')\n",
    "print('y:', y, sep='\\n', end='\\n\\n')\n",
    "print('bias:', model.intercept_)\n",
    "print('pesos:', model.coef_, end='\\n\\n')\n",
    "print('probabilidades:', p_pred, sep='\\n', end='\\n\\n')\n",
    "print('classes estimadas:', y_pred, end='\\n\\n')\n",
    "print('acurácia:', score_, end='\\n\\n')\n",
    "print('matriz de confusão:', conf_m, sep='\\n', end='\\n\\n')\n",
    "print('relatório:', report, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesse caso, 2 amostras foram classificadas erroneamente, como mostrado na figura a seguir:\n",
    "\n",
    "<img src=\"assets/log-reg-8.webp\" alt=\"regularized\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A figura acima revela uma característica importante da regressão logística: Ela não resolve problemas que não sejam linearmente separáveis. Em outras palavras, não é possível encontrar uma reta que separe as amostras, nesse caso, de forma a conseguir $100\\%$ de acurácia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exemplo 3 - Reconhecendo Dígitos\n",
    "\n",
    "O proximo exemplo lida com uma abordagem de problema do mundo real, de reconhecimento de imagem, com multiplas classes. Para isso, utilizaremos um dataset composto por 1797 imagens de digitos de $8\\times8$ pixels, representados por um vetor de $64$ posições."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Passo 1: importando os pacotes\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensões x: (1797, 64)\n",
      "Dimensões y: (1797,)\n",
      "x=\n",
      "[[ 0.  0.  5. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ... 10.  0.  0.]\n",
      " [ 0.  0.  0. ... 16.  9.  0.]\n",
      " ...\n",
      " [ 0.  0.  1. ...  6.  0.  0.]\n",
      " [ 0.  0.  2. ... 12.  0.  0.]\n",
      " [ 0.  0. 10. ... 12.  1.  0.]]\n",
      "y=\n",
      "[0 1 2 ... 8 9 8]\n"
     ]
    }
   ],
   "source": [
    "# Passo 2a: importando os dados\n",
    "\n",
    "x, y = load_digits(return_X_y=True)\n",
    "\n",
    "print('Dimensões x:', x.shape)\n",
    "print('Dimensões y:', y.shape)\n",
    "print('x=', x, sep='\\n')\n",
    "print('y=', y, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Passo 2b: dividindo os dados em conjunto de treino e conjunto de teste\n",
    "\n",
    "# Conjunto de treino é usado para ajustar o modelo (encontrar o bias e os pesos), \n",
    "#    enquanto o conjunto de testes é usado para avaliar o quão bom o modelo é para predizer casos\n",
    "#    desconhecido, ou seja, amostras que não foram utilizadas no treinamento.\n",
    "\n",
    "# Essa divisão é geralmente feita de modo aleatório, sendo que, geralmente, 70% a 80% dos dados é usado pra\n",
    "#    treinamento e o restante para teste\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Passo 2c: Normalizando os dados\n",
    "\n",
    "# A maioria dos algoritmos de aprendizado de máquina funcionam melhor com dados normalizados, ou seja, \n",
    "#   transformando os dados de modo que todas as características (features) tenham média zero e desvio\n",
    "#   padrão igual a 1.\n",
    "\n",
    "# Para normalizar os dados, seguimos 3 passos:\n",
    "#   1 - computar a média e o desvio padrão de cada coluna de x (feature)\n",
    "#   2 - subtrair o valor de cada característica pela média de sua coluna\n",
    "#   3 - dividir essa diferença pelo desvio padrão da coluna.\n",
    "\n",
    "# O processo pode ser feito usando a função .fit_transform() do pacote \n",
    "#    sklearn.preprocessing.StandardScaler:\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.05, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='ovr', n_jobs=None, penalty='l2', random_state=0,\n",
       "                   solver='liblinear', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Passo 3: Criando e treinando o modelo\n",
    "\n",
    "# Processo bem parecido com o anterior. Note que selecionamos 'ovr' para o hiper-parâmetro \n",
    "#   multi_class. O objetivo é fazer a abordagem de classificação binária para cada classe (one-versus-all).\n",
    "model = LogisticRegression(solver='liblinear', C=0.05, multi_class='ovr',\n",
    "                           random_state=0)\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Material baseado em: https://realpython.com/logistic-regression-python/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit ('torchEnv': conda)",
   "language": "python",
   "name": "python37764bittorchenvconda44a76b6c90fa48eea1939354f840259c"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
